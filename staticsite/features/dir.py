from __future__ import annotations

import logging
import os
from typing import TYPE_CHECKING, Optional

from staticsite.feature import Feature
from staticsite.page import Page, PageValidationError

if TYPE_CHECKING:
    from staticsite import file, structure
    from staticsite.site import Site
    from staticsite.utils.typing import Meta

log = logging.getLogger("dir")


class Dir(Page):
    """
    Page with a directory index
    """
    TYPE = "dir"

    def __init__(self, site: Site, *, name: Optional[str] = None, **kw):
        super().__init__(site, **kw)
        # Directory name
        self.name: Optional[str] = name
        # Subdirectory of this directory
        self.subdirs: list["Dir"] = []
        # Files found in this directory
        self.files: dict[str, file.File] = {}

        # Pages loaded from this directory
        self.pages = []

        self.meta["build_path"] = os.path.join(self.meta["site_path"], "index.html").lstrip("/")

    # def analyze(self):
    #     # Finalize from the bottom up
    #     for subdir in self.subdirs:
    #         subdir.analyze()

    #     self.meta["pages"] = [p for p in self.pages if not p.meta["draft"]]
    #     self.meta.setdefault("template", "dir.html")
    #     self.meta["build_path"] = os.path.join(self.meta["site_path"], "index.html").lstrip("/")

    #     self.meta["indexed"] = bool(self.meta["pages"]) or any(p.meta["indexed"] for p in self.subdirs)
    #     self.meta.setdefault("syndicated", False)

    #     self.meta.setdefault("parent", self.dir)
    #     if self.dir is not None:
    #         self.meta["title"] = os.path.basename(self.src.relpath)

    #     # TODO: set draft if all subdirs and pages are drafts

    #     # Since analyze is called from the bottom up, subdirs have their date
    #     # up to date
    #     self.subdirs.sort(key=lambda p: p.meta["date"])
    #     self.meta["pages"].sort(key=lambda p: p.meta["date"])

    #     date_pages = []
    #     if self.subdirs:
    #         date_pages.append(self.subdirs[-1].meta["date"])
    #     if self.meta["pages"]:
    #         date_pages.append(self.meta["pages"][-1].meta["date"])

    #     if date_pages:
    #         self.meta["date"] = max(date_pages)
    #     else:
    #         self.meta["date"] = self.site.localized_timestamp(self.src.stat.st_mtime)

    #     if self.meta["indexed"] and self.meta["site_path"] not in self.site.structure.pages:
    #         self.site.add_page(self)

    # def validate(self):
    #     try:
    #         super().validate()
    #     except PageValidationError as e:
    #         log.error("%s: infrastructural page failed to validate: %s", e.page, e.msg)
    #         raise


class DirPages(Feature):
    """
    Build indices of directory contents.

    When a directory has no index page but contains pages, this will generate
    the index page listing all pages in the directory.
    """
    RUN_BEFORE = ["autogenerated_pages"]

    def add_missing_indices(self, entry: structure.Entry):
        """
        Add a missing Page to the given entry and all its children, when it's
        missing
        """
        # We work top-down, so the parent node, if it exists, always has a page set
        if entry.page is None:
            if entry.parent is None:
                meta = self.site.metadata.derive(self.site._settings_to_meta())
                meta["site_path"] = "/"
            else:
                meta = self.site.metadata.derive(entry.parent.meta)
                meta["site_path"] = os.path.join(entry.parent.meta["site_path"], entry.name)
            page = Dir(self.site, name=entry.name, meta=meta)
            self.site.add_page(page)

        if entry.sub:
            for entry in entry.sub.values():
                self.add_missing_indices(entry)

    def analyze(self):
        self.add_missing_indices(self.site.structure.root)


FEATURES = {
    "dirs": DirPages,
}
